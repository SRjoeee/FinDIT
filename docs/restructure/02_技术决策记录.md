# FindIt 技术决策记录

> **版本**: v1.1
> **日期**: 2026-02-11
> **适用范围**: 全部技术选型的决策理由和变更历史
> **格式**: ADR (Architecture Decision Record)

---

## 目录

- [第一部分：代码质量基线](#第一部分代码质量基线)
- [第二部分：搜索引擎决策](#第二部分搜索引擎决策)
- [第三部分：视觉分析决策](#第三部分视觉分析决策)
- [第四部分：媒体处理决策](#第四部分媒体处理决策)
- [第五部分：性能优化决策](#第五部分性能优化决策)
- [第六部分：已废弃的决策](#第六部分已废弃的决策)

---

# 第一部分：代码质量基线

## 1.1 现有代码质量评估

分析范围：全部核心源码 59 文件 (~13,243 LOC) + 测试 35 文件 (~7,706 LOC)

| 维度 | 评分 | 说明 |
|------|------|------|
| 代码简洁性 | **8.0/10** | enum 纯函数命名空间、VisionField 单一信息源、清晰错误类型 |
| 系统架构 | **9.0/10** | 双层 SQLite、三层分离、多级回退链、断点续传 |
| 运行性能 | **7.5/10** | VectorStore BLAS 加速、合并 FFmpeg 调用、三层跳过检测 |
| 技术选型 | **9.0/10** | GRDB/WhisperKit/FFmpeg 均为最优选择 |

### 1.2 已确认的优秀设计模式

- **enum + static methods**: PipelineManager、SearchEngine、SyncEngine、SceneDetector 均为无状态命名空间，天然线程安全
- **VisionField 单一信息源**: 9 字段元数据枚举，动态生成 SQL 列名、SET 子句、JSON schema、prompt，新增字段改动从 ~13 处减至 6 处
- **EmbeddingProvider 协议**: 嵌入向量协议化，支持 Gemini/NLEmbedding 双实现和回退
- **三层跳过检测**: file_size + file_modified → xxHash-128 → DB 状态检查，99% 已索引视频在层 1 跳过

### 1.3 已确认需改进的问题

| 问题 | 严重度 | 当前状态 | 改进方案 |
|------|--------|---------|---------|
| PipelineManager.processVideo() 约 500 行 | 重要 | 单函数过长 | 拆分为独立阶段方法，或重写为 LayeredIndexer |
| processVideo() 参数 13 个 | 中等 | 参数过多 | 封装为 ProcessingContext 结构体 |
| 原始 SQL 散落在多个模块 | 中等 | PipelineManager 内有直接 SQL | 收敛到 Model extension 或 Repository 层 |
| SearchResult 构造冗余 | 低 | 每个搜索方法重复构造 | 提取 SearchResult.from(row:) 工厂方法 |

---

# 第二部分：搜索引擎决策

## ADR-015: USearch HNSW 作为唯一向量索引引擎

**日期**: 2026-02-11
**状态**: 已决定
**替代**: Accelerate 暴力扫描 (现有)、FAISS、sqlite-vss、sqlite-vec、自研 HNSW

### 背景

FindIt 目标支持 10-20TB 视频素材（10 万 ~ 120 万 clips）。现有 Accelerate/vDSP 暴力扫描在 100K clips 时 25ms 可接受，但 120 万 clips 时 307ms 不可接受（键入即搜场景）。

### 数据规模估算

| 素材总量 | 视频均大小 | 视频数 | clips/视频 | 总 clip 数 | FP16 内存 |
|---------|----------|--------|-----------|-----------|----------|
| 10TB | 500MB | 20,480 | 20 | 409,600 | 0.6 GB |
| 20TB | 500MB | 40,960 | 30 | 1,228,800 | 1.8 GB |

### 候选方案排除

| 方案 | 搜索延迟 (1M) | Swift 兼容 | 排除原因 |
|------|-------------|-----------|---------|
| Accelerate 暴力 | 250ms | 原生 | 大数据量瓶颈 |
| FAISS | 3ms (HNSW) | C FFI | macOS 无 AMX 支持，NEON 有限，维护成本极高 |
| sqlite-vss | 50ms | 不兼容 GRDB | macOS 系统 SQLite 不允许加载第三方扩展 |
| sqlite-vec | 800ms | 不兼容 GRDB | 比暴力更慢 |
| 自研 HNSW | ~1ms | 原生 | 参数调优需大量实验，开发风险高 |
| IVF | 15ms | 需自研 | recall 不如 HNSW，需 K-means 训练 |
| PQ | 40ms | 需自研 | 精度损失大 (recall 85%)，Swift 无现成实现 |

### 决策

选择 **USearch HNSW FP16**:

| 优势 | 详情 |
|------|------|
| 官方 Swift SPM | `import USearch` 直接用，第一方维护 |
| ARM NEON 原生 | 内置 Apple Silicon SIMD 内核 |
| 亚毫秒搜索 | 120 万 clips < 1ms |
| mmap 加载 | 索引文件内存映射，App 启动零延迟 |
| FP16 量化 | 内存减半，recall 仅损失 ~1% |
| 增量更新 | add/remove 接口，无需重建整个索引 |
| 线程安全 | 内置读写锁，并发搜索 + 串行写入 |

### 参数配置

- 维度: 768 (SigLIP-base)
- M (connectivity): 16
- efConstruction: 200
- efSearch: 64
- 量化: FP16
- 索引路径: `~/Library/Application Support/FindIt/vector.usearch`（缓存，可从 SQLite BLOB 重建）

### 性能预估 (120 万 clips)

| 指标 | 数值 |
|------|------|
| 搜索延迟 | < 1ms |
| 内存占用 | ~1.1 GB (mmap 可按需加载) |
| 索引文件大小 | ~1.0 GB |
| Recall@10 | ~93-94% |
| App 启动加载 | mmap 模式 ≈ 0ms |

### 与现有架构的集成

**双索引架构**: CLIP 向量和文本嵌入向量在不同嵌入空间，不能混合搜索，需要两个独立索引。

```
SQLite BLOB（source of truth，向量持久化）
    ↓ App 启动时 / 索引完成时
USearch HNSW 索引 A: clip_vectors (CLIP space, L1)
    → 关键帧 CLIP 向量, 搜索时用 CLIP text encoder 编码查询
USearch HNSW 索引 B: text_embeddings (text embedding space, L3)
    → VLM 描述文本嵌入, 搜索时用 EmbeddingGemma/Gemini 编码查询
    ↓ 搜索时分别调用
SearchEngine 三路融合: FTS5 + USearch-A (CLIP) + USearch-B (text) → 加权排序
```

---

## ADR-016: 以图搜视频功能

**日期**: 2026-02-11
**状态**: 已决定
**来源**: MaterialSearch 竞品分析

### 背景

MaterialSearch 已有此功能。CLIP 嵌入空间同时包含图片和文本，实现成本极低。

### 决策

- 利用 CLIP 跨模态嵌入空间支持图片查询
- 流程: 用户输入图片 → CLIP image encoder → USearch 搜索 → 返回视觉相似片段
- 接口: `SearchEngine.searchByImage(imageData: Data) -> [SearchResult]`

---

## ADR-017: 负向查询支持

**日期**: 2026-02-11
**状态**: 已决定
**来源**: MaterialSearch 竞品分析

### 决策

- 搜索语法: `-关键词` 或 `NOT 关键词`
- FTS5 层: 生成排除条件 `NOT 关键词`
- 向量层: `final_score = cosine(query, clip) - λ × cosine(neg_query, clip)`，λ 默认 0.5

---

## ADR-018: LRU 嵌入缓存

**日期**: 2026-02-11
**状态**: 已决定
**来源**: memvid 竞品分析

### 决策

- 文本查询 embedding 增加 LRU 缓存（容量 256 条）
- 相同查询不重复调用模型推理

---

## ADR-009: 混合搜索融合排序 (现有，保持)

**日期**: Stage 3
**状态**: 保持

### 核心设计

- final_score = α × normalize(fts_rank) + β × cosine_similarity
- FTS5 rank 是负 BM25 值，需 min-max 归一化
- 自适应权重:
  - 引号→exactMatch(0.9/0.1)
  - 长句(>10 字)→semantic(0.2/0.8)
  - 默认(0.4/0.6)

### 重构后的修订

重构后增加 CLIP 向量搜索路径，融合为三路。**注意: CLIP 向量和文本嵌入向量在不同嵌入空间，需要两个独立的 USearch 索引，不能混合搜索。**

自适应权重策略（根据可用数据层自动调整）:

| 场景 | CLIP 向量 | FTS5 | 文本嵌入 | 说明 |
|------|----------|------|---------|------|
| L1 完成 (仅 CLIP) | **0.7** | 0.3 | 0.0 | 索引后立即可搜，FTS5 靠 tags/filename |
| L1+L2 完成 | **0.6** | 0.4 | 0.0 | STT 转录丰富了 FTS5 |
| L1+L2+L3 完成 | **0.5** | 0.2 | 0.3 | 三路融合最优 |
| 引号精确匹配 | 0.1 | **0.8** | 0.1 | FTS5 主导 |
| 长句 (>10 字) | **0.6** | 0.1 | 0.3 | CLIP 语义理解主导 |
| 图片查询 | **1.0** | 0.0 | 0.0 | 纯 CLIP 跨模态 |

---

# 第三部分：视觉分析决策

## CLIP 模型选择: google/siglip2-base-patch16-224

**日期**: 2026-02-11
**状态**: 已确定 (2026-02-11 调研 + Spike 验证)

### 背景

重构核心是从"间接搜索"(图像→文字描述→文字嵌入→搜索) 转为"直接搜索"(图像→CLIP 视觉嵌入 ←→ CLIP 文字嵌入←搜索)。

### 候选模型

| 模型 | 来源 | 维度 | 参数量 | 多语言 | 优势 | 备注 |
|------|------|------|--------|--------|------|------|
| **SigLIP2-base** | google/siglip2-base-patch16-224 | 768 | ~86M | **100+ 语言** (Gemma 256K tokenizer) | XM3600 多语言检索 40.7%, ImageNet 79.1% | **已确定** |
| Chinese-CLIP ViT-B/16 | 阿里达摩院 | 512 | ~150M | 中文特化 | 2 亿中文图文对训练 (MUGE R@1=63%) | 中文增强可选 |
| MobileCLIP2-B | Apple 2025 | 不明确 | 86M+63M | **英文 only** | DFNDR-2B 英文过滤数据集, 无官方 CoreML | **排除** |
| MobileCLIP-B | Apple 2024 | 512/768 | 87M | 英文 | 精度高 (76.8% ImageNet) | 不支持中文 |
| MobileViCLIP-Small | Apple | 512 | 47.9M | 英文 | 理解时序动作（8帧 segment） | FindIt 已有场景检测，收益有限 |
| Jina-CLIP-v2 | Jina AI | 1024 | 0.9B | 89 语言 | 最强多语言 | 参数量大 |
| EmbeddingGemma-300M | Google DeepMind 2025 | 768 | 308M | 100+ 语言 | MTEB <500M 第一, 纯文本 embedding, 非 CLIP | **本地 text embedding 采用** |

### 决策理由

1. **SigLIP2-base 已确定**:
   - SigLIP2 (2025-02) 而非 SigLIP1 (2024)——多语言检索 (XM3600) 从 22.5% 提升至 40.7%
   - 768d 与现有 Gemini embedding-001 维度完全一致
   - Gemma 256K tokenizer，覆盖 100+ 语言（用户要求"全语言"而非仅中文）
   - Spike 验证已通过：Vision 87ms, Text 46ms, 100% 匹配准确率

2. **MobileCLIP2 排除**:
   - 训练数据 DFNDR-2B 为英文过滤数据集，论文自认 "English-only data limits capabilities"
   - 无任何非英语评估（XM3600 未测）
   - 无官方 CoreML 版本（仅 MobileCLIP v1 有 CoreML）
   - 嵌入维度不明确

3. **CLIP 文字搜视频为核心搜索路径 (R2a)**:
   - CLIP text encoder 编码查询文字 → 在 CLIP 向量空间搜索关键帧向量 = **文字搜视频的最优路径**
   - 不依赖 VLM 描述质量（解决"信息瓶颈"），索引速度快 15-60x
   - 以图搜视频作为附带能力（CLIP 天然支持，无额外成本）
   - 推理后端: ONNX Runtime (Spike 已验证)，CoreML EP 作为性能升级路径

4. **Spike 已完成验证** (2026-02-11):
   - Vision 87ms, Text 46ms (分离模型), 768d, 100% 匹配准确率
   - 详见 MEMORY.md SigLIP2 CLIP Spike 结果

### SigLIP2 集成注意事项 (Spike 踩坑记录)

| # | 问题 | 影响 | 解法 |
|---|------|------|------|
| 1 | **swift-sentencepiece 返回 1-indexed token IDs** | 所有 token +1 偏移，匹配率 0% | `tokenIds.map { Int32($0) - 1 }` |
| 2 | **ONNX Runtime FP16 图优化 Bug** | `.all` 优化级别产生**静默错误结果** | 必须 `.none` (禁用所有优化) |
| 3 | **INT8 ConvInteger(10) 不支持** | ORT 1.20 不支持此算子，INT8 模型完全不可用 | 只能用 FP16 |
| 4 | **合并模型内存 ~2GB** | model_fp16.onnx (716MB) 运行两个 encoder | 用分离模型 + 投影权重 |

### 生产部署方案

**分离模型 + 手动投影** (推荐):
- `vision_model_fp16.onnx` (177MB) + `text_model_fp16.onnx` (538MB)
- 从合并模型提取投影矩阵权重，推理后手动应用
- 性能: Vision ~87ms, Text ~46ms (比合并模型快 40-65%)
- 内存: ~500MB (比合并模型 ~2GB 减少 75%)
- 懒加载: 索引时加载 vision encoder，搜索时加载 text encoder

### CLIP 搜索质量分析

#### 优势场景

| 查询类型 | 示例 | 预期质量 | 说明 |
|---------|------|---------|------|
| 场景/环境 | "海滩" "城市夜景" | 极好 | CLIP 训练数据中场景描述丰富 |
| 常见物体 | "红色汽车" "一只猫" | 很好 | 视觉-语义对齐充分 |
| 风格/氛围 | "cinematic" "暖色调" | 较好 | 视觉风格理解能力强 |
| 抽象概念 | "快乐" "孤独" | 尚可 | 能捕捉到情绪氛围 |

#### 弱势场景（CLIP 固有限制 — Bag-of-Words 问题）

| 查询类型 | 示例 | 预期质量 | 问题根因 |
|---------|------|---------|---------|
| 属性绑定 | "穿红衣服的男人和穿蓝衣服的女人" | 差 | CLIP 无法正确绑定属性到对象 |
| 空间关系 | "左边是猫，右边是狗" | 差 | CLIP 对空间位置关系不敏感 |
| 计数 | "三个人在桌旁" | 差 | 计数能力弱 |
| 时序动作 | "正在跌倒" | 差 | 单帧无法理解动态过程 |
| 文字 OCR | "写着 EXIT 的标志" | 差 | CLIP 对图片中文字理解弱 |

**影响程度**: 约 70% 实际查询不受影响（场景级查询），20% 轻微影响，10% 严重影响。弱势场景可通过 FTS5 + VLM 文本描述补充搜索部分弥补。

### 整体效果预估

| 维度 | 当前方案 (VLM+FTS5) | CLIP-First | 差异 |
|------|---------------------|-----------|------|
| 搜索质量（加权） | 80/100 | 73-78/100 | -2~-7（可通过 L3 VLM 弥补） |
| 搜索体验（加权） | 42/100 | 95/100 | **+53（质的飞跃）** |

---

## ~~Gemini embedding 完全移除~~

**日期**: 2026-02-11
**状态**: ~~已决定~~ → **已撤回** (2026-02-11 修订)

### 原决策

完全移除 Gemini text-embedding-004 依赖。

### 撤回理由

1. CLIP 跨模态搜索降为 P3 远期目标后，文字搜索仍是核心路径
2. 当前全链路是文本对文本：VLM 看图→文字描述→text embedding→768d 向量
3. Gemini embedding-001 作为在线 text embedding 质量高、768d，应保留为付费用户/在线模式

### 修订决策: 本地/云端双轨 Text Embedding

**在线**: Gemini gemini-embedding-001 (768d) — 保留，付费用户优先
**离线**: EmbeddingGemma-300M (ONNX Q8, 768d) — 新增，替代 NLEmbeddingProvider
**维度一致**: 两者均 768d，索引向量可互相搜索，无需双索引

---

## 本地 Text Embedding: EmbeddingGemma-300M 替代 NLEmbedding (ADR-019)

**日期**: 2026-02-11
**状态**: 已决定

### 背景

现有离线回退方案 NLEmbeddingProvider (Apple NLEmbedding, 512d) 有两个致命问题：
1. **维度不兼容**: 512d vs Gemini 768d，离线时向量搜索完全失效
2. **质量低**: 词级别 word embedding 取平均，不理解语序和语义组合

### 决策

采用 Google DeepMind EmbeddingGemma-300M (ONNX Q8) 作为本地 text embedding 引擎。

| 项目 | NLEmbedding (旧) | EmbeddingGemma (新) |
|------|------------------|---------------------|
| 维度 | 512d | **768d (与 Gemini 一致)** |
| 质量 | 词向量平均 | **MTEB <500M 第一名** |
| 多语言 | 逐语言加载 | **100+ 语言统一** |
| 模型大小 | 系统内置 | Q8 ~300MB / Q4 <200MB |
| 离线能力 | ✅ | ✅ |
| 与 Gemini 兼容 | ❌ 维度不同 | ✅ **同 768d 可混合索引** |

### 集成方式

- onnxruntime-swift-package-manager (Package.swift 已有注释, 取消注释即可)
- 模型文件: onnx-community/embeddinggemma-300m-ONNX (HuggingFace)
- Tokenizer: Gemma 256K vocab, swift-transformers 加载

### 分层策略

| 用户类型 | 索引时 | 搜索时 | 离线搜索 |
|---------|--------|--------|---------|
| 免费用户 | EmbeddingGemma 本地 768d | EmbeddingGemma 本地 | 正常工作 |
| 付费用户 | Gemini embedding-001 云端 768d | Gemini embedding-001 | 回退到 EmbeddingGemma |

---

## 免费/付费分层架构 (ADR-020)

**日期**: 2026-02-11
**状态**: 已决定

### 背景

产品需要同时服务免费用户和付费用户，免费用户必须完全离线可用且效果好。

### 决策

| 层 | 免费用户 | 付费用户 | 差异 |
|---|---|---|---|
| **L1 CLIP 向量** | SigLIP2 本地 (768d, 87ms/帧) | 同左 | **无差异** |
| **L2 STT + FTS5** | WhisperKit/SpeechAnalyzer 本地 | 同左 | **无差异** |
| **L3 VLM 描述** | LocalVLM Qwen3-VL (6/9 字段) | Gemini 3.0 Flash (9/9 字段) | **付费更准** |
| **L3 Text Embedding** | EmbeddingGemma 本地 (768d) | Gemini embedding-001 云端 (768d) | **付费略优** |

### 核心原则

1. **文字搜索效果和速度第一** — CLIP 核心路径解决
2. **完全离线必须可用且效果好** — L1 CLIP + L2 STT 全部本地，零网络依赖
3. **付费用户获得更好的 L3 描述质量** — Gemini VLM + Gemini embedding，弥补 CLIP 弱势场景
4. **CLIP 和 text embedding 均为 768d**，但在不同嵌入空间，需独立索引

### VLM 升级路径

- Gemini 2.5 Flash → **Gemini 3.0 Flash** (2026-01 发布, 性能超 2.5 Pro, $0.50/1M input tokens)
- 注意: Gemini 系列**不提供跨模态 embedding**，只做 VLM + text embedding

### 云端多模态 embedding (远期可选)

- **Vertex AI multimodalembedding@001**: 图+文+视频同一 1408d 空间, $0.0001/张
- 需要独立索引 (1408d vs SigLIP2 768d)，作为付费用户可选增强
- 当前 SigLIP2 本地 CLIP 已足够好，此项优先级低

---

## 视觉分析三级回退 (现有，保持)

**日期**: Stage 3.5
**状态**: 保持

```
Gemini Flash (云) → LocalVLMAnalyzer (Qwen3-VL-4B 本地) → LocalVisionAnalyzer (Apple Vision)
```

重构后此回退链保留作为 Layer 3（文本描述增强层）。核心搜索走 CLIP 向量 (L1)，L3 描述作为补充增强，弥补 CLIP 在属性绑定、空间关系、计数等弱势场景的不足。L3 也是**付费用户差异化**的主要来源（Gemini 3.0 Flash >> LocalVLM）。

---

# 第四部分：媒体处理决策

## MediaService 协议抽象层

**日期**: 2026-02-11
**状态**: 已决定

### 背景

当前 FFmpeg 调用硬编码在 SceneDetector、KeyframeExtractor、AudioExtractor 三个文件中，无法扩展到 AVFoundation 或专业 SDK。

### 决策

引入 MediaDecoder/MediaService 协议族，GStreamer 风格的路由引擎：

```
应用层 (PipelineManager)
    ↓ 只依赖 MediaService 协议
CompositeMediaService (路由层)
    ├── AVFoundation (P:100, 系统内置)
    ├── BRAW SDK (P:150, 专业格式)
    ├── FFmpeg (P:50, 通用降级)
    └── Sidecar Metadata (P:10, 仅元数据)
```

### 改动范围

```
需要重构的代码: ~25%
  - PipelineManager.swift → 注入 MediaService 替代 FFmpegConfig
  - FFmpegBridge → 降级为 FFmpegDecoder 内部实现

不动的代码: ~75%
  - SearchEngine, VectorStore, Database, Models, Sync, App 层, CLI
```

### 为什么不完全移除 FFmpeg

| 原因 | 说明 |
|------|------|
| MKV 支持 | AVFoundation 不支持 MKV |
| 场景检测 | FFmpeg select='gt(scene,threshold)' 成熟方案 |
| DNxHD/DNxHR | Avid 中间格式，AVFoundation 不支持 |
| 音频提取 | FFmpeg 音频重采样成熟可靠 |

### 为什么不只用 FFmpeg

| 原因 | 说明 |
|------|------|
| 专有 RAW 无法解码 | R3D, BRAW, CRM, X-OCN, ARRIRAW |
| 进程开销大 | 每次调用都是子进程 |
| 硬件加速弱 | 不如 AVFoundation 原生 VideoToolbox |
| 需用户安装 | AVFoundation 零安装依赖 |

---

## AVFoundation 替代 FFmpeg 的可行性

**日期**: 2026-02-08
**状态**: 可行，但需混合策略

### 格式覆盖

AVFoundation 可覆盖约 85-90% 的视频素材格式，剩余 10-15% 需 FFmpeg 降级。

### 已知雷点

1. **MKV 容器不支持** — 方案: FFmpeg remux (`-c copy`, 1-5 秒/文件，纯 I/O)
2. **Swift Concurrency 兼容问题** — AVAssetReader 在 actor 内可能挂起。方案: 用专用 DispatchQueue 隔离 AVFoundation 操作
3. **场景检测无内置** — 方案: 复用 CLIP 帧间向量差异（零额外开销）或保留 FFmpeg 场景检测

---

## 专业相机格式支持策略

**日期**: 2026-02-08
**状态**: 已决定

### 格式矩阵

| 品牌 | RAW 格式 | 扩展名 | SDK 名称 | 是否免费 |
|------|---------|--------|---------|---------|
| Blackmagic | BRAW | .braw | BRAW SDK | 完全免费 |
| RED | REDCODE RAW | .R3D | REDlib | 商业授权 |
| ARRI | ARRIRAW | .ari | ARRI Image SDK | 商业授权 |
| Canon | Cinema RAW Light | .CRM | Canon RAW Dev SDK | 限制性 |
| Sony | X-OCN | .mxf | Sony RAW Driver | 合作协议 |

### 优先级

1. **BRAW SDK** — 免费、文档好、用户量大
2. **RED** — 市场占有率高，可先依赖 RED Apple Workflow Installer
3. **ARRI/Canon/Sony** — 按用户需求后续添加

### macOS Media Extensions 前瞻

Apple WWDC 2024 推出 MediaExtension.framework (macOS 15)。如果 RED/Blackmagic 等厂商发布 Media Extensions，FindIt 的 AVFoundation 路径将自动获得支持。

---

# 第五部分：性能优化决策

## P0 优化项

### ProcessInfo 后台活动声明

**问题**: 缺少 macOS 后台任务保护，App 进入后台后系统可能降低进程优先级。

**方案**:
- `ProcessInfo.processInfo.beginActivity(options: [.userInitiated, .idleSystemSleepDisabled])`
- 在 processQueue() 入口/出口调用
- 效果: 防止系统休眠 + 保持进程优先级

### 进度回调节流

**问题**: 并行处理 8 个视频时，MainActor 每秒接收 8-16 个 Task 调度。

**方案**: 时间窗口节流（500ms），MainActor 更新频率从 ~16次/秒降到 ~2次/秒。

## P1 优化项

### FFmpeg 异步化

**问题**: `FFmpegBridge.run()` 使用 `Process.waitUntilExit()` 阻塞 Swift 并发线程。

**方案**: 改为 `terminationHandler` + `withCheckedThrowingContinuation` 异步等待，释放 Swift 并发线程。

### 用户活跃度感知调度

**问题**: 需要在用户无感知的情况下自动完成索引。

**方案**: `CGEventSource.secondsSinceLastEventType()` 检测用户空闲，活跃时强制 background 模式。

### SyncEngine PreparedStatement

**问题**: Clip 同步循环中每条记录都解析 SQL，SQL 解析开销约占 15-20%。

**方案**: GRDB PreparedStatement 预编译，SQL 解析只执行一次。

### Vision 阶段写事务合并

**问题**: 每分析完一个 clip 执行两次独立写事务，50 个场景 → 100 次 WAL 同步。

**方案**: 每 10 个 clip 合并一次写事务，写 I/O 减少 ~80%。

## P2 优化项

| 优化项 | 影响 | 工作量 |
|--------|------|--------|
| 文件夹间并行处理 | 中 | 1d |
| 网络断线容错 (NWPathMonitor) | 中 | 4h |
| processVideo() 重构 | 低 | 2d |

## P3 优化项

| 优化项 | 影响 | 工作量 |
|--------|------|--------|
| VectorStore partial sort (O(N+K log K)) | 低 | 2h |
| 夜间自动索引 (NSBackgroundActivityScheduler) | 低 | 3h |
| SearchResult 工厂方法 | 低 | 1h |

---

# 第六部分：已废弃的决策

## ~~MobileViCLIP 作为核心搜索引擎~~

**原文档**: 002、005、006
**废弃原因**: FindIt 已有场景检测做了时序分割，视频级时序理解额外收益有限。SigLIP 768 维表达能力更强且天然多语言。

## ~~Accelerate 暴力扫描作为唯一向量搜索~~

**原文档**: 002、003
**废弃原因**: 120 万 clips 时 307ms 不可接受。USearch HNSW FP16 在任何数据量级都更优（< 1ms）。

## ~~Gemini text-embedding-004 作为可选 embedding provider~~

**原文档**: Stage 3
**废弃原因**: CLIP 同时编码图像和文本，不再需要 text-only embedding。完全移除以消除网络依赖。

## ~~FastVLM 0.5B 作为本地 VLM~~

**原文档**: 005
**废弃原因**: 项目已有 LocalVLMAnalyzer (Qwen3-VL-4B)。重构后 VLM 描述降级为 Layer 3 可选增强，不再是核心路径，现有方案已足够。

## ~~Jina-CLIP-v2 作为主力嵌入模型~~

**原文档**: 002、003
**废弃原因**: 0.9B 参数过大，不适合资源受限场景。SigLIP-base 在精度和效率间取得更好平衡。作为后备方案保留。

## ~~NLEmbeddingProvider 作为离线 embedding 回退~~

**原文档**: Stage 3
**废弃原因**: 512d 与 Gemini 768d 维度不兼容，离线时向量搜索完全失效。词级别 embedding 取平均质量极低。由 EmbeddingGemma-300M (768d, ONNX) 替代。

## ~~CLIP 跨模态降为 P3 远期目标~~

**原文档**: 重构文档 v1.0
**废弃原因**: Spike 验证 CLIP 文字搜视频可行且性能优异 (87ms/帧, 46ms/查询, 100% 匹配)。CLIP **恢复为 R2a 核心路径**——它本质上就是文字搜视频的最优方案，不是"以图搜视频"的附属功能。

## ~~完全移除 Gemini text embedding~~

**原文档**: 重构文档初版
**废弃原因**: Gemini embedding-001 保留为付费用户 Layer 3 文本描述的在线 embedding。与 EmbeddingGemma 同为 768d，离线可回退。

---

## 附录: 现有 ADR 索引

| ADR | 主题 | 阶段 | 状态 |
|-----|------|------|------|
| ADR-001~007 | Stage 0-2 基础决策 | Stage 0-2 | 保持 |
| ADR-008 | 双层 SQLite 存储 | Stage 1 | 保持 |
| ADR-009 | 混合搜索融合排序 | Stage 3 | 保持（权重修订） |
| ADR-010 | clips.tags JSON 数组格式 | Stage 1 | 保持 |
| ADR-011 | Gemini 免费额度管理 | Stage 2c | 保持（重构后重要性降低） |
| ADR-012 | SRT 降级存储路径 | Stage 2b | 保持 |
| ADR-013 | VisionField 单一信息源 | Stage 3.7 | 保持 |
| ADR-014 | IndexingScheduler 资源池并行 | Stage 4 | 保持 |
| ADR-015 | USearch HNSW 向量索引 | 重构 | **新增** |
| ADR-016 | 以图搜视频 (CLIP 附带能力) | 重构 | **新增** |
| ADR-017 | 负向查询支持 | 重构 | **新增** |
| ADR-018 | LRU 嵌入缓存 | 重构 | **新增** |
| ADR-019 | EmbeddingGemma 替代 NLEmbedding | 重构 | **新增** |
| ADR-020 | 免费/付费分层架构 | 重构 | **新增** |

---

> **文档结束**
> 架构设计详见 `03_架构与设计规格.md`，执行计划详见 `04_重构执行路线图.md`
